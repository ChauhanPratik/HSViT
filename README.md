# ğŸ§  HSViT: Hierarchically Scaled Vision Transformer for Brain Tumor Detection

This repository contains the full implementation of **HSViT**, a novel Transformer-based architecture for brain tumor localization, classification, and boundary estimation on the FigShare dataset. HSViT enhances the DSViT framework through innovations like Cross-Layer Attention Refinement (CLAR), Tumor Context Modules (TCM), and progressive token filtering.

---

## ğŸš€ Key Highlights

- ğŸ”€ **Cross-Layer Attention Refinement (CLAR)**  
- ğŸ§  **Tumor Context Module (TCM)** â€“ biasing attention to tumor zones  
- âœ‚ï¸ **Progressive Token Importance Filtering** â€“ keeps only essential tokens  
- ğŸ¯ **Dual Decoder Head** â€“ predicts tumor class + boundary map  
- ğŸ§ª **Ablation-ready Backbone** â€“ modular toggles for fair comparison  
- ğŸ”¬ **Neuro-Attentive Pre-Encoder** â€“ enhances low-contrast slices early

---

## ğŸ“ Project Structure

```
BRAINTUMOR/
â”œâ”€â”€ DATASET/
â”‚   â”œâ”€â”€ FILES/                        # .mat MRI slices
â”‚   â””â”€â”€ cvind.mat                     # Split metadata
â”‚
â”œâ”€â”€ HSViT/
â”‚   â”œâ”€â”€ hsvit/
â”‚   â”‚   â”œâ”€â”€ model.py                 # Full backbone + decoding
â”‚   â”‚   â”œâ”€â”€ dataset.py              # PyTorch dataset w/ preprocessing
â”‚   â”‚   â”œâ”€â”€ preprocessor.py         # CLAHE, Skull Stripping, Smoothing
â”‚   â”‚   â”œâ”€â”€ hooks.py                # Feature visualization hooks
â”‚   â”‚   â”œâ”€â”€ utils.py                # Metrics, plots
â”‚   â”‚   â””â”€â”€ modules/
â”‚   â”‚       â”œâ”€â”€ pre_encoder.py
â”‚   â”‚       â”œâ”€â”€ clar.py
â”‚   â”‚       â”œâ”€â”€ token_filter.py
â”‚   â”‚       â”œâ”€â”€ tcm.py
â”‚   â”‚       â””â”€â”€ decoder_head.py
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ 1_EDA.ipynb
â”‚       â”œâ”€â”€ 2_3_VISUALIZE_ADVANCED_PREPROCESSING.ipynb
â”‚       â”œâ”€â”€ 4_FEATURE_EXTRACTION.ipynb
â”‚       â”œâ”€â”€ 5_DATA_GENERATOR.ipynb
â”‚       â”œâ”€â”€ 6_TRAIN.ipynb
â”‚       â”œâ”€â”€ TRAIN-TEST-TEST.ipynb   # Fast sanity-check on 10 images
â”‚       â”œâ”€â”€ 7_TEST.ipynb
â”‚       â”œâ”€â”€ 8_INTERMEDIATE_FEATURES.ipynb
â”‚       â”œâ”€â”€ 9_EVALUATION_RESULTS.ipynb
â”‚       â””â”€â”€ 10_ABLATION_STUDY.ipynb
```

---

## ğŸ”§ Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

> âœ… Python â‰¥ 3.9 recommended

---

## âš™ï¸ Training & Inference

### ğŸ”¹ Full Model Training

```python
# Inside 6_TRAIN.ipynb
model = ViTBackbone(
    use_clar=True,
    use_tcm=True,
    use_boundary_head=True
)
...
```

### ğŸ”¹ Quick Test on Few Images

```python
# Inside TRAIN-TEST-TEST.ipynb
outputs = model(images)
```

---

## ğŸ“ˆ Evaluation Metrics

Use the following notebooks for full metrics:

- **`9_EVALUATION_RESULTS.ipynb`** â€“ Accuracy, F1, Precision, Recall, Confusion Matrix, ROC-AUC
- **`8_INTERMEDIATE_FEATURES.ipynb`** â€“ Token retention, heatmaps, TCM/CLAR impact
- **`10_ABLATION_STUDY.ipynb`** â€“ Compare variants without CLAR, TCM, or boundary decoder

---

## ğŸ§ª Ablation Variants

All models are trained and evaluated under fair splits with identical settings.

| Variant              | CLAR | TCM  | Boundary Head |
|----------------------|------|------|----------------|
| âœ… Full HSViT        | âœ…    | âœ…    | âœ…              |
| âŒ No CLAR           | âŒ    | âœ…    | âœ…              |
| âŒ No TCM            | âœ…    | âŒ    | âœ…              |
| âŒ No Boundary Head  | âœ…    | âœ…    | âŒ              |

Check `10_ABLATION_STUDY.ipynb` for results and visual comparisons.

---

## ğŸ–¼ï¸ Sample Visuals

- âœ… Preprocessing stages: CLAHE, skull stripping, smoothing  
- âœ… PreEncoder vs Raw MRI comparison  
- âœ… Token norm heatmaps & filtering  
- âœ… CLS token evolution across modules  
- âœ… Boundary map predictions and class labels  
- âœ… Confusion matrix, ROC curve overlays  

---

## ğŸ“£ Citation

> Will be updated upon publication.

---

## ğŸ§© Acknowledgements

This project uses the publicly available [FigShare brain tumor dataset](https://figshare.com/articles/dataset/brain_tumor_dataset/1512427).
